{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that I have all the images downloaded\n",
    "\n",
    "I can now see if I can use Optical Character Recognition to read text from cards. \n",
    "\n",
    "If I can I can first to extract the card name and then narrowing down the set of cards to compare in our vector database via cosine similarity. \n",
    "\n",
    "I want to utilize a pretrained model to embed the card images and store them in a vector database. A user will then upload a picture from their phone of a card and it will use the OCR to find text in the card and then narrow down the search in the database to only those cards. It will then use cosine similarity to compare the overall card images to find the exact match.\n",
    "\n",
    "This will lead to a reduced search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract  # Python library for OCR (Optical Character Recognition)\n",
    "from PIL import Image # PIL is the Python Imaging Library, which provides the imaging capabilities for PILLOW\n",
    "\n",
    "# Set the Tesseract executable path\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "\n",
    "def extract_card_name(image_path):\n",
    "    # Load image with PIL\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Perform OCR on the image\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    \n",
    "    # Post-process the OCR result to extract the card name (e.g., via regex)\n",
    "    # This assumes the card name appears at the top of the card\n",
    "    card_name = text.splitlines()[0]  # Naive assumption that the first line is the card name\n",
    "    \n",
    "    return card_name.strip()\n",
    "\n",
    "# def extract_all_text(image_path):\n",
    "#     # Preprocess the image\n",
    "#     processed_img = preprocess_image(image_path)\n",
    "    \n",
    "#     # Perform OCR with custom configuration\n",
    "#     config = '--oem 3 --psm 3'  # OEM 3: Default, PSM 3: Fully automatic page segmentation\n",
    "#     text = pytesseract.image_to_string(processed_img, config=config)\n",
    "    \n",
    "#     return text\n",
    "\n",
    "def extract_all_text(image_path):\n",
    "    # Load image with PIL\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Perform OCR on the image\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results were strange so lets clean up the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Load the image using OpenCV\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply thresholding to binarize the image\n",
    "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # Optional: Apply GaussianBlur to reduce noise\n",
    "    blur = cv2.GaussianBlur(thresh, (3, 3), 0)\n",
    "    \n",
    "    # Convert back to PIL format for pytesseract\n",
    "    processed_img = Image.fromarray(blur)\n",
    "    \n",
    "    return processed_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essence Warden\n",
      "\n",
      "serene\n",
      "\n",
      "Whenever another ci\n",
      "battlefield, you gain 1\n",
      "\n",
      "aera oar\n",
      "\n",
      "\"Life begets li\n",
      "\n",
      "0126 / 1158\n",
      "| PRM + EN 16 Goran Josie\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(extract_all_text('Datasets/mtg_images/000a7263-37e6-4246-82f9-94459517a5cc.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to segment to image to only grab the card name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siren Lookout\n"
     ]
    }
   ],
   "source": [
    "def segment_image(image_path):\n",
    "    # Load the image using OpenCV\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Get the image dimensions\n",
    "    height, width = img.shape[:2]\n",
    "    \n",
    "    # Define relative ROIs based on percentages of the image size\n",
    "    card_name_roi = img[int(0.05 * height):int(0.15 * height), int(0.07 * width):int(0.8 * width)]  # Adjust percentages as needed\n",
    "    \n",
    "    # Convert ROIs to PIL format for pytesseract\n",
    "    card_name_img = Image.fromarray(card_name_roi)\n",
    "    \n",
    "    return card_name_img\n",
    "\n",
    "def extract_card_name_from_segment(image_path):\n",
    "    # Segment the image into regions\n",
    "    card_name_img = segment_image(image_path)\n",
    "    \n",
    "    # Perform OCR on the card name region\n",
    "    config = '--oem 3 --psm 6'\n",
    "    card_name_text = pytesseract.image_to_string(card_name_img, config=config)\n",
    "    \n",
    "    return card_name_text.strip()\n",
    "\n",
    "\n",
    "print(extract_card_name_from_segment('Datasets/mtg_images/0000cd57-91fe-411f-b798-646e965eec37.jpg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MtG_Classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
